# Example config file for syncS3toS3 script in blobstore mode.

[main]
# debug > 0 spits out tons of debugging output
debug=0
# number of concurrent copy threads
nthreads=4
# mode to specify format of ids (default mode ws)
mode=blobstore
# mongo creds for source db
mongo_host=localhost
mongo_database = blobstore
mongo_user = blobstore
mongo_pwd = BLAH
# mongo collection to query (usually s3_objects in ws mode, nodes in blobstore mode)
mongo_collection=nodes
# key field in collection (usually key in ws mode, id in blobstore mode)
mongo_keyfield=id
# datestamp for beginning date to start with
# (defaults to 'now', rewritten to 'now' at the end of script)
datefile=blobstoresync.last
# log successful copied objects (also used to skip copying next run)
logfile=blobstoresync.log
# objects that failed to copy (for whatever reason)
# this file is first read, then emptied, when the script is run
retryfile=blobstoresync.retry
# remove log before starting copy
resetlog=0
# path to mc minio client
mcpath=/opt/mc/mc
# for large files, where to download tmp files for mc to upload
tmpdir=/path/to/mc/download/dir
# larger than this will download to tmpdir and use mc to upload
# smaller than this uses put_object which reads entire object into memory
# nthreads*sizelimit should not exceed available RAM
sizelimit=5000000000

[source]
# source S3 instance (currently only mc client uses)
bucket = blobstore
# destination S3 config used by boto (to test whether target object already exists)
url = https://storage.googleapis.com
accessKey = BLAH
secretKey = BLAH
region = us-central-1
# whether remote uses self-signed cert
insecure=0

[destination]
# destination S3 instance
# mcendpoint uses .mc/config.json labels
mcendpoint = dests3
bucket = blobstore
# destination S3 config used by boto (to test whether target object already exists)
url = https://storage.googleapis.com
accessKey = BLAH
secretKey = BLAH
region = us-central-1
# whether remote uses self-signed cert
insecure=0
